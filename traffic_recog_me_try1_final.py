# -*- coding: utf-8 -*-
"""Traffic_Recog_me_try1_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yeTYTa8Yepsd2yF2Pv7A8uFjFnSRPjBp
"""

import keras
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
!pip install scikit-learn
from sklearn.metrics import accuracy_score

import urllib.request

print('Beginning file download...')

url = 'https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/traffic-signs-data.zip'

urllib.request.urlretrieve(url, './traffic-signs-data.zip')

import zipfile
import os


print('Beginning file unzip')

zip_ref = zipfile.ZipFile('./traffic-signs-data.zip', 'r')
zip_ref.extractall('./')
zip_ref.close()

print('Done')
os.listdir("./")

# Load pickled data
import pickle

# TODO: Fill this in based on where you saved the training and testing data

training_file = './train.p'
validation_file= './valid.p'
testing_file = './test.p'

with open(training_file, mode='rb') as f:
    train = pickle.load(f)
with open(validation_file, mode='rb') as f:
    valid = pickle.load(f)
with open(testing_file, mode='rb') as f:
    test = pickle.load(f)
    
X_train, y_train = train['features'], train['labels']
X_valid, y_valid = valid['features'], valid['labels']
X_test, y_test = test['features'], test['labels']

print(y_train)

import numpy as np
import pandas as pd

### Replace each question mark with the appropriate value. 
### Use python, pandas or numpy methods rather than hard coding the results

# TODO: Number of training examples
n_train = X_train.shape[0]

# TODO: Number of validation examples
n_validation = X_valid.shape[0]

# TODO: Number of testing examples.
n_test = X_test.shape[0]

# TODO: What's the shape of an traffic sign image?
image_shape = X_train.shape[1:]

# TODO: How many unique classes/labels there are in the dataset.
n_classes = len(np.unique(y_train))

print("Number of training examples =", n_train)
print("Number of testing examples =", n_test)
print("Number of validation examples =", n_validation)
print("Image data shape =", image_shape)
print("Number of classes =", n_classes)

# Commented out IPython magic to ensure Python compatibility.
def show_images(images, cols = 1, titles = None):
    """Display a list of images in a single figure with matplotlib.
    
    Parameters
    ---------
    images: List of np.arrays compatible with plt.imshow.
    
    cols (Default = 1): Number of columns in figure (number of rows is 
                        set to np.ceil(n_images/float(cols))).
    
    titles: List of titles corresponding to each image. Must have
            the same length as titles.
    """
    assert((titles is None)or (len(images) == len(titles)))
    
    n_images = len(images)
    
    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]
    
    fig = plt.figure(figsize=(2, 2))
    
    for n, (image, title) in enumerate(zip(images, titles)):
        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)
        a.grid(False)
        a.axis('off')
        if image.ndim == 2:
            plt.gray()
        plt.imshow(image, cmap='gray')
        a.set_title(title)
    
    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)
    plt.show()
    
def select_random_images_by_classes(features, labels, n_features):
  
  indexes = []
  _classes = np.unique(labels);
  
  while len(indexes) < len(_classes):
  
    index = random.randint(0, n_features-1)
    _class = labels[index]

    for i in range(0, len(_classes)):

      if _class == _classes[i]:
        _classes[i] = -1
        indexes.append(index)
        break

  images = []
  titles = []

  for i in range(0, len(indexes)):
    images.append(features[indexes[i]])
    titles.append("class " + str(labels[indexes[i]]))

  show_images(images, titles = titles)
### Data exploration visualization code goes here.
### Feel free to use as many code cells as needed.
import matplotlib.pyplot as plt
import random
# Visualizations will be shown in the notebook.
# %matplotlib inline

#select_random_images_by_classes(X_train, y_train, n_train)

def plot_distribution_chart(x, y, xlabel, ylabel, width, color):
  
  plt.figure(figsize=(15,7))
  plt.ylabel(ylabel, fontsize=18)
  plt.xlabel(xlabel, fontsize=16)
  plt.bar(x, y, width, color=color)
  plt.show()
_classes, counts = np.unique(y_train, return_counts=True)

plot_distribution_chart(_classes, counts, 'Classes', '# Training Examples', 0.7, 'blue')

print('Transforming Images')
import cv2

def augment_brightness_camera_images(image):
    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)
    random_bright = .25+np.random.uniform()
    #print(random_bright)
    image1[:,:,2] = image1[:,:,2]*random_bright
    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)
    return image1

def transform_image(img,ang_range,shear_range,trans_range,brightness=0):
    '''
    This function transforms images to generate new images.
    The function takes in following arguments,
    1- Image
    2- ang_range: Range of angles for rotation
    3- shear_range: Range of values to apply affine transform to
    4- trans_range: Range of values to apply translations over.

    A Random uniform distribution is used to generate different parameters for transformation

    '''
    # Rotation

    ang_rot = np.random.uniform(ang_range)-ang_range/2
    rows,cols,ch = img.shape    
    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)

    # Translation
    tr_x = trans_range*np.random.uniform()-trans_range/2
    tr_y = trans_range*np.random.uniform()-trans_range/2
    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])

    # Shear
    pts1 = np.float32([[5,5],[20,5],[5,20]])

    pt1 = 5+shear_range*np.random.uniform()-shear_range/2
    pt2 = 20+shear_range*np.random.uniform()-shear_range/2

    # Brightness

    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])

    shear_M = cv2.getAffineTransform(pts1,pts2)

    img = cv2.warpAffine(img,Rot_M,(cols,rows))
    img = cv2.warpAffine(img,Trans_M,(cols,rows))
    img = cv2.warpAffine(img,shear_M,(cols,rows))

    if brightness == 1:
      img = augment_brightness_camera_images(img)

    return img

print('Adding Images')
images = []

for i in range(0, 100):
  images.append(transform_image(X_train[555],10,5,5,brightness=1))

#show_images(images)

for _class, count in zip(_classes, counts):
  new_images = []
  new_classes = []
  
  if count < 1000:
    y_train_length = y_train.shape[0]
    index = 0
    
    for i in range(0, 1000-count):
      while y_train[index] != _class:
        index = random.randint(0, y_train_length-1)
      new_images.append(transform_image(X_train[index],10,5,5,brightness=1))
      new_classes.append(_class)
      
    X_train = np.concatenate((X_train, np.array(new_images)))
    y_train = np.concatenate((y_train, np.array(new_classes)))
    
_classes, counts = np.unique(y_train, return_counts=True)

plot_distribution_chart(_classes, counts, 'Classes', '# Training Examples', 0.7, 'blue')

#check dimentions

n_train = X_train.shape[0]

print("Number of training examples =", n_train)

X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)

X_test_gray = np.sum(X_test/3, axis=3, keepdims=True)

X_valid_gray = np.sum(X_valid/3, axis=3, keepdims=True)

# check grayscale images
#select_random_images_by_classes(X_train_gray.squeeze(), y_train, n_train)

print('Gray and Normalization')
X_train_gray -= np.mean(X_train_gray)

X_test_gray -= np.mean(X_test_gray)

X_train = X_train_gray

X_test = X_test_gray

print('Splitting Data')
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.20, random_state=43)
X_train, y_train = shuffle(X_train, y_train)

print("Testing Data :",X_test.shape[0])
X_test, y_test = shuffle(X_test, y_test)

print(X_test.shape)

from google.colab import drive
drive.mount('/content/drive')

testcases = 10000
#print(a)
f= open("testcase_store_1.dat","w+")
for image in range(0,testcases):
  temp = X_test[image]
  temp2 = temp.flatten()
  a = list(temp2)
  #print(a.shape)
  for item in range(0,1024):
    if(item == 1023):
      f.write("%s" % temp2[item])
    else:
      f.write("%s," % temp2[item])
  f.write("\n")
f.close()
#    for item in a:
     #   f.write("%s," % item)

!rm -rf train_data
#select_random_images_by_classes(X_train_gray.squeeze(), y_train, n_train)
#plt.imshow(X_train[100])
#from keras.preprocessing.image import save_img
#!mkdir train_data
f= open("test_data_labels_1.txt","w+")
print(X_train.shape)
for i in range(testcases):
  #temp = X_train[i]
  #print(temp.shape)
  #plt.imshow(temp.squeeze(), cmap='gray')
  #plt.plot(X_train[100])
  #pic_name = './train_data/train_' + str(i) + '.bmp'
  #print(pic_name)
  f.write("%d\n" % (y_test[i]))
  #save_img(pic_name, temp)
f.close()

!mkdir ./drive/temp
!cp testcase_store_1.dat ./drive/MyDrive/ColabNotebooks/

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

print('Creating Model')
model = Sequential()

model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='linear',padding='same', input_shape=(32,32,1)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=16, kernel_size=(5, 5),padding='same', activation='linear'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Permute((2,3,1),input_shape=(1,8,8,16)))

model.add(Flatten(data_format='channels_first'))

model.add(Dense(120, activation='relu'))

model.add(Dense(84, activation='relu'))

model.add(Dense(43, activation = 'softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam',
                metrics=['accuracy'])
#model.compile(optimizer='adam')


print(model.summary())

"""# Truncated model"""

from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Permute

layer1 = Input(shape=(32, 32, 1))
layer2 = Conv2D(filters=6, kernel_size=(5, 5), activation='linear',padding='same')(layer1)
layer3 = MaxPooling2D(pool_size=(2, 2))(layer2)
layer4 = Conv2D(filters=16, kernel_size=(5, 5),padding='same', activation='linear')(layer3)
layer5 = MaxPooling2D(pool_size=(2, 2))(layer4)
layer6 = Permute((2,3,1),input_shape=(1,8,8,16))(layer5)
layer7 = Flatten(data_format='channels_first')(layer6)
layer8 = Dense(120, activation='relu')(layer7)
layer9 = Dense(84, activation='relu')(layer8)
layer10 = Dense(43, activation='linear')(layer9)


modelTrun = Model(inputs=layer1, outputs=layer10)

model.layers

modelTrun.layers

modelTrun.layers[1].set_weights(model.layers[0].get_weights())
print(modelTrun.layers[1].name)
modelTrun.layers[3].set_weights(model.layers[2].get_weights())
print(model.layers[2].get_weights()[0].shape)
modelTrun.layers[7].set_weights(model.layers[6].get_weights())
print(model.layers[2].get_weights()[0].shape)
print(model.layers[6].get_weights()[0])
modelTrun.layers[8].set_weights(model.layers[7].get_weights())
modelTrun.layers[9].set_weights(model.layers[8].get_weights())
#modelTrun.layers[7].set_weights(model.layers[6].get_weights())

print(X_train[0])
print(y_train[0])

testImg = []
with open("data_1.txt", "r") as handle:
  pixels = handle.readline().split(",")

pixels[-1] = pixels[-1].replace("\n", '')

for pixel in pixels:
  testImg.append(float(pixel))
testImg = np.array(testImg)

testImg = testImg.reshape(32, 32)

plt.imshow(testImg, cmap='gray')

testImg = X_train[0]
print(testImg.shape)
print(testImg)

print(X_test.shape)

import evaluate

print(y_test.shape)

out.shape

out = model.predict(X_test.reshape(12630, 32, 32, 1))
out_class = out.argmax(axis=1)
accuracy_score(out_class, y_test) * 100.0

out.shape

print(out.size)
#print(out[0,:,:,0])
print(out[0,:])

"""OLD"""

print(out.size)
print(out.shape)
print(out[0,:,:,0])
#print(out[0,:])

print(len(X_train))
print(X_train.shape)
print(y_train.shape)
y_train_labels = y_train

from keras.utils import to_categorical
y_train_labels = to_categorical(y_train_labels)
print(y_train_labels.shape)

y_validation_labels = y_validation
from keras.utils import to_categorical
y_validation_labels = to_categorical(y_validation_labels)
print(y_validation_labels.shape)

history = model.fit(X_train, y_train_labels, epochs=10, validation_data=(X_validation, y_validation_labels))

from keras.utils import plot_model
plot_model(model, to_file='model.png',expand_nested= True,show_shapes=True)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

layer_no = 2 # 2,0
for layer_no in [0,2]:
  kernelWidth = model.layers[layer_no].get_weights()[0].shape[0]
  kernelHeight = model.layers[layer_no].get_weights()[0].shape[1]
  kernelDepth = model.layers[layer_no].get_weights()[0].shape[2]
  print("Kernel Width : ", kernelWidth)
  print("Kernel Height : ", kernelHeight)
  print("Kernel Depth : ", kernelDepth)
  numChannels = model.layers[layer_no].get_weights()[0].shape[3]
  print("Num Channels : ", numChannels)
  fileName = model.layers[layer_no].name
  fileName += ".txt"
  fileHandler = open(fileName, "w")
  for channels in range(0, numChannels):
    for depth in range(kernelDepth):
      for width in range(kernelWidth):
        for height in range(kernelHeight):
          fileHandler.write(str(model.layers[layer_no].get_weights()[0][width, height, depth, channels]) + " ")
  fileHandler.write("\n")
  # Store biases
  for channels in range(0, numChannels):
    fileHandler.write(str(model.layers[layer_no].get_weights()[1][channels]) + " ");
  fileHandler.close()

# Fully connected
for fc_layer in [6,7,8]:
  #fc_layer = 7   # 5,6,7
  inputFeatures = model.layers[fc_layer].get_weights()[0].shape[0]
  outFeatures = model.layers[fc_layer].get_weights()[0].shape[1]
  print("Input features dim : ", inputFeatures)
  print("Out Features dim : ", outFeatures)
  fileName = model.layers[fc_layer].name
  fileName += ".txt"
  fileHandler = open(fileName, "w")
  for outFeature in range(0, outFeatures):
    for inFeature in range(0, inputFeatures):
      fileHandler.write(str(model.layers[fc_layer].get_weights()[0][inFeature][outFeature]) + " ")
  fileHandler.write("\n")

  for bias in range(0, outFeatures):
    fileHandler.write(str(model.layers[fc_layer].get_weights()[1][bias]) + " ")
  fileHandler.close()

# Storing Convolution layer
#for no_layers in [0,2]:
 # print(no_layers)
  #layer_weights_all = model.layers[no_layers].get_weights()[0]
  #layer_biases_all  = model.layers[no_layers].get_weights()[1]
  #print(model.layers[no_layers].name)
  #print(layer_weights_all.shape)
  #file_name = model.layers[no_layers].name + '.txt'
  #f= open(file_name,"w+")
  #for filter_no in range(0,layer_weights_all.shape[3]):
  #  data = layer_weights_all[:,:,:,filter_no].flatten()
  #  for index in range(0,len(data)):
  #    f.write("%f " % (data[index]))
  #f.write("\n")
  #for bias_index in range(0,len(layer_biases_all)):
  #  f.write("%f "% layer_biases_all[bias_index])
  #f.close()
  #print(len(data))
  #a = tuple(first_layer_weights)
  #!echo "$data" >> "$file_name"
  
#print((first_layer_weights))
#print((first_layer_biases))

# Storing FC data
#for no_layers in [5,6,7]:
 # print(no_layers)
  #layer_weights_all = model.layers[no_layers].get_weights()[0]
  #layer_biases_all  = model.layers[no_layers].get_weights()[1]
  #print(model.layers[no_layers].name)
  #print(layer_weights_all.shape)
  
  #file_name = model.layers[no_layers].name + '.txt'
  
  #f= open(file_name,"w+")
  #for row_no in range(0,layer_weights_all.shape[0]):
  #  data = layer_weights_all[row_no,:].flatten()
  #  for index in range(0,len(data)):
  #    f.write("%f " % (data[index]))
  #f.write("\n")
  #for bias_index in range(0,len(layer_biases_all)):
  #  f.write("%f "% layer_biases_all[bias_index])
  #f.close()